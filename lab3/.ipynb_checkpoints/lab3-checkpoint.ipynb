{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metody jądrowe (kernel methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konfiguracja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Użyjemy bardzo standardowych narzędzi, tych samych, co na laboratorium 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install numpy scipy pandas matplotlib scikit-learn missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duży zbiór danych do klasyfikacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Użyjemy najpierw bioinformatycznego zbioru danych [Cod-RNA](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#cod-rna). Pochodzi on z artykułu ([link do wersji Open Access](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-7-173)):\n",
    "\n",
    "> Uzilov, Andrew V., Joshua M. Keegan, and David H. Mathews. *\"Detection of non-coding RNAs on the basis of predicted secondary structure formation free energy change.\"* BMC bioinformatics 7.1 (2006): 1-30. [link](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-7-173)\n",
    "\n",
    "[Centralny dogmat biologii molekularnej (central dogma of molecular biology)](https://en.wikipedia.org/wiki/Central_dogma_of_molecular_biology) mówi, że przepływ informacji genetycznej przebiega z DNA przez RNA do białek. Innymi słowy, DNA zapisuje informację biologiczną, którą potem koduje RNA, z którego są syntezowane białka.\n",
    "\n",
    "W praktyce nie każde DNA i RNA koduje informacje. Kodujące DNA to zaledwie ok. 1-2% ludzkiego genomu, a reszta pełni różne role, głównie regulacyjne. W szczególności [niekodujące RNA (non-coding RNA, ncRNA)](https://en.wikipedia.org/wiki/Non-coding_RNA) pełni wiele różnych zadań, na przykład:\n",
    "- budują rybosomy odpowiadające za syntezę białek ([rRNA](https://en.wikipedia.org/wiki/Ribosomal_RNA))\n",
    "- transportują informację genetyczną ([tRNA](https://en.wikipedia.org/wiki/Transfer_RNA))\n",
    "- regulują ekspresję genów ([lncRNA](https://en.wikipedia.org/wiki/Long_non-coding_RNA))\n",
    "\n",
    "Nie są znane wszystkie funkcje niekodującego RNA, więc jest to aktywne pole badań. Najpierw trzeba jednak sprawdzić, czy dane RNA w ogóle jest kodujące, czy nie. Taka klasyfikacja jest nieoczywista, i też stanowi pole badań w bioinformatyce. Niektóre hipotezy wskazują, że struktura drugorzędowa RNA ma tutaj znacznie.\n",
    "\n",
    "Struktura pierwszorzędowa kwasu nukleinowego (DNA lub RNA) to po prostu liniowa sekwencja nukleotydów, np. ACCUUGCAUC. Struktura drugorzędowa oznacza ułożenie par nukleotydów (np. G-C, A-U) jednego lub dwóch łańcuchów.  Dla DNA to typowo podwójna helisa, natomiast RNA tworzy już bardzo bogate i złożone struktury. Przewidywanie struktury wyższego rzędu to typowe zadanie ML w bioinformatyce, bo sprawdzanie tego eksperymentalnie jest bardzo drogie.\n",
    "\n",
    "![nucleic_acid_structures.png](nucleic_acid_structures.png)\n",
    "\n",
    "Przykładem algorytmu przewidującego strukturę drugorzędową jest [Dynalign](https://www.sciencedirect.com/science/article/abs/pii/S0022283601953513). Opiera się on na obserwacji, że niektóre struktury drugorzędowe RNA są bardziej stabilne od innych. Struktury o niższej energii są, zgodnie z zasadami termodynamiki, wolniejsze, a zatem stabilniejsze i bardziej prawdopodobne. Algorytm ten dodatkowo realizuje **dopasowanie sekwencji (sequence alignment)**, czyli takie \"przyłożenie\" do siebie sekwencji RNA, żeby jak najwięcej par pasowało do siebie. Wejściem do niego są 2 sekwencje RNA, a wyjściem ilość wolnej energii w optymalnej strukturze drugorzędowej RNA - im mniejsza, tym stabilniejsza jest struktura.\n",
    "\n",
    "Artykuł, z którego pochodzi nasz zbiór danych, zaproponował zastosowanie ML do klasyfikacji, czy dwie sekwencje RNA stanowią niekodujące RNA (ncRNA), czy też nie. Zbiór treningowy zbudowano z blisko 60 tysięcy par sekwencji RNA pochodzących z sekwencjonowania genomu bakterii *Escherichia coli* oraz *Salmonella enterica serovar Typhi (Salmonella typhi)*. Klasą pozytywną jest niekodujące RNA (5S rRNA albo tRNA), a negatywną losowo przemieszane nukleotydy z prawdziwej pary (istnieją do tego algorytmy tzw. sequence shuffling). Klasy są w stosunku 1:2, więc mamy klasyfikację lekko niezbalansowaną. Analogicznie stworzono zbiór testowy o wielkości nieco ponad 270 tysięcy par.\n",
    "\n",
    "Jako cech użyto:\n",
    "- wartości z algorytmu Dynalign\n",
    "- długości krótszej sekwencji\n",
    "- częstotliwości zasad azotowych A/U/C w sekwencji 1 (3 cechy)\n",
    "- częstotliwości zasad azotowych A/U/C w sekwencji 2 (3 cechy)\n",
    "\n",
    "Mamy zatem klasyfikację binarną, umiarkowanie niezbalansowaną, i 8 cech numerycznych. Jako metryk autorzy używają precyzji, czułości, krzywych ROC oraz wartości AUROC.\n",
    "\n",
    "My dla uproszczenia użyjemy F1-score, czyli średniej harmonicznej precyzji (precision) i czułości (recall). Obliczanie prawdopodobieństw w SVMach jest kosztowne i daje raczej niskiej jakości predykcje prawdopodobieństw, więc AUROC nie jest dla nich zbyt wygodną metryką."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oryginalny zbiór jest w formacie `svmlight`, z którego korzystają biblioteki LibSVM i Liblinear. Są one standardowymi implementacjami SVMów. Sam ten format danych jest jednak tekstowy i zajmuje bardzo dużo miejsca, dlatego w tym repozytorium jest już przetworzony do formatu Parquet. Wczytamy teraz dane.\n",
    "\n",
    "Później trzeba dokonać normalizacji cech, tak jak zawsze w SVMach. Tak jak autorzy, wykonamy skalowanie min-max do zakresu [-1, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 1 (0.5 punktu)**\n",
    "\n",
    "1. Wczytaj dane treningowe z plików `cod_rna_train.parquet` oraz `cod_rna_test.parquet`.\n",
    "2. Wyodrębnij kolumnę `y` do osobnych zmiennych `y_train` oraz `y_test`.\n",
    "3. Dokonaj skalowania danych do zakresu [-1, 1], tworząc tablice `X_train_scaled` oraz `X_test_scaled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet(\"cod_rna_train.parquet\")\n",
    "X_test = pd.read_parquet(\"cod_rna_test.parquet\")\n",
    "\n",
    "y_train = X_train.pop(\"y\")\n",
    "y_test = X_test.pop(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/przemek/.local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skoro dane są gotowe, to wytrenujmy nasz pierwszy klasyfikator - liniowy SVM.\n",
    "\n",
    "W Scikit-learn funkcja kosztu (`loss`) to albo typowy hinge loss, albo squared hinge loss, czyli po prostu podniesiona do kwadratu. Wartość domyślna to `\"squared_hinge\"` - żeby dostać \"typowego\" SVMa, trzeba to zmienić. Jest różniczkowalna i mocniej kara duże błędy, ale jest też bardziej podatna na outliery. Dla zainteresowanych: [przystępny tutorial](https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-hinge-squared-hinge-loss-with-keras.md) oraz artykuł naukowy:\n",
    "\n",
    "C.P. Lee, and C.J. Lin. *\"A study on L2-loss (squared hinge-loss) multiclass SVM.\"* Neural computation 25.5 (2013): 1302-1323.\n",
    "\n",
    "Dodatkowo domyślna liczba iteracji solwera (1000) jest często dość niska, szczególnie przy dużych zbiorach. Zwiększymy to od razu, żeby mieć mniej warningów. Powyżej 10 tysięcy iteracji warningami można się już zazwyczaj nie przejmować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 93.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "clf_linear_svc = LinearSVC(loss=\"hinge\", max_iter=10000, random_state=0)\n",
    "clf_linear_svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = clf_linear_svc.predict(X_test_scaled)\n",
    "print(f\"F1-score: {100 * f1_score(y_test, y_pred):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liniowy SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 2 (0.5 punktu)**\n",
    "\n",
    "Wytrenuj regresję logistyczną jako nasz **model baseline'owy**. Nasze bardziej złożone modele SVM muszą być od niego lepsze, żeby był w ogóle sens je rozważać.\n",
    "\n",
    "Użyj regularyzacji L2. Dokonaj tuningu siły regularyzacji (100 wartości) za pomocą 5-krotnej walidacji skrośnej. Jako metryki do tuningu użyj F1-score.\n",
    "\n",
    "Użyj zbalansowanych wag klas. W razie potrzeby zwiększ maksymalną liczbę iteracji solwera. Może się przydać `n_jobs`. Pamiętaj o ustawieniu `random_state=0`.\n",
    "\n",
    "Sprawdź wyniki algorytmu na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/przemek/.local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/przemek/.local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/przemek/.local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/przemek/.local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/przemek/.local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 93.28%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "\n",
    "clf_log_reg = LogisticRegressionCV(\n",
    "    Cs=100,\n",
    "    penalty=\"l2\",\n",
    "    class_weight=\"balanced\",\n",
    "    scoring=\"f1\",\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    ").fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = clf_log_reg.predict(X_test_scaled)\n",
    "print(f\"F1-score: {100 * f1_score(y_test, y_pred):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nasz SVM bez żadnego tuningu jest zasadniczo tak dobry, jak regresja logistyczna z tuningiem - całkiem nieźle. No ale czas teraz na tuning samego SVMa.\n",
    "\n",
    "Najpierw warto wiedzieć jeszcze parę rzeczy o implementacji użytej w Scikit-learn, korzystającej pod spodem z Liblinear.\n",
    "\n",
    "Argument `dual` wyznacza, czy skorzystać z postaci primal, czy dual. Jeżeli liczba próbek jest znacznie większa od liczby cech, albo ogółem mamy sporo próbek, to lepiej użyć primal `dual=False`. Niestety, wtedy mamy do dyspozycji tylko funkcję kosztu `squared_hinge`.\n",
    "\n",
    "SVM jest stricte jednowątkowy (sekwencyjny), więc równoległość można wykorzystać przy tuningu hiperparametrów. Zdecydowanie warto użyć tu `n_jobs=-1`.\n",
    "\n",
    "**Uwaga:** jako że osobne joby są tworzone jako osobne procesy, to wyłączenie `ConvergenceWarning` jest nietrywialne, a czasem niemożliwe. Sugeruję to po prostu zignorować.\n",
    "\n",
    "**Zadanie 3 (1 punkt)**\n",
    "\n",
    "Dokonaj tuningu hiperparametru `C` liniowego SVM. Użyj 5-krotnej walidacji skrośnej, wybierając model o najwyższym F1-score. Użyj zbalansowanych wag klas i funkcji kosztu hinge loss. Pamiętaj o stałym `random_state`.\n",
    "\n",
    "Zastosuj iteracyjne zagęszczanie siatki. Najpierw sprawdź wartości z zakresu `[1e-3, 1e-2, 1e-1, 1, 1e1, 1e2]` i znajdź optymalną wartość `C`. Następnie wedle własnego uznania zagęść siatkę wokół znalezionego optymalnego C. Może się przydać `np.linspace()` albo `list(range())`. Jeżeli w takiej operacji wychodzi optymalne `C` na granicy (najmniejsze albo największe możliwe), to warto sprawdzić większe wartości niż dotychczas rozważane. Powtórz takie działanie 2-3 razy. W praktyce jednak `C` większe niż kilkaset nie ma sensu w kontekście SVMów.\n",
    "\n",
    "Wypisz ostatecznę znalezioną optymalną wartość odwrotności siły optymalizacji `C`. Sprawdź wynik na zbiorze testowym. Czy udało się przebić baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/przemek/.local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/przemek/.local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/przemek/.local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([17.2933075 , 15.6780314 , 15.22121072, 15.05624294, 11.69722762]), 'std_fit_time': array([1.77027443, 1.54873309, 2.02816061, 1.53921535, 2.70176807]), 'mean_score_time': array([0.0128181 , 0.00976477, 0.00991201, 0.00956559, 0.00570831]), 'std_score_time': array([0.00639701, 0.00059565, 0.00055755, 0.00167219, 0.00162973]), 'param_C': masked_array(data=[190.0, 192.5, 195.0, 197.5, 200.0],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 190.0}, {'C': 192.5}, {'C': 195.0}, {'C': 197.5}, {'C': 200.0}], 'split0_test_score': array([0.8322898 , 0.83564132, 0.83316274, 0.83180906, 0.82391542]), 'split1_test_score': array([0.9222624 , 0.92132179, 0.90998277, 0.87508723, 0.88251593]), 'split2_test_score': array([0.94711127, 0.90710759, 0.92210526, 0.93066256, 0.93546845]), 'split3_test_score': array([0.8641115 , 0.92630058, 0.91653505, 0.92296651, 0.85261797]), 'split4_test_score': array([0.9123718 , 0.91218638, 0.91049131, 0.90098879, 0.92454425]), 'mean_test_score': array([0.89562936, 0.90051153, 0.89845543, 0.89230283, 0.8838124 ]), 'std_test_score': array([0.04158194, 0.0331243 , 0.0329456 , 0.03589721, 0.04216599]), 'rank_test_score': array([3, 1, 2, 4, 5], dtype=int32)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/przemek/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\"C\": np.linspace(190, 200, 5)}\n",
    "linear_svm_cv = GridSearchCV(LinearSVC(), param_grid, scoring=\"f1\", n_jobs=-1)\n",
    "linear_svm_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(linear_svm_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/C = 0.005194805194805195\n"
     ]
    }
   ],
   "source": [
    "print(f\"1/C = {1 / linear_svm_cv.best_params_['C']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 91.69%\n"
     ]
    }
   ],
   "source": [
    "y_pred = linear_svm_cv.predict(X_test_scaled)\n",
    "print(f\"F1-score: {100 * f1_score(y_test, y_pred):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nie udało się przebić baseline'u. Fine tuning wywiódł mnie na manowce i uzysakałem wynik gorszy niż dla domyślnego. Podczas \"zbiegania\" do uzyskanego C zauważyłem, że jest to wysoce niestabilne i czasami uzyskiwałem wynik lepszy/gorszy o kilka procent przy małych zmianach C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Może się to jeszcze uda poprawić - w końcu w artykule autorzy używali kernel SVM, a nie liniowego!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel SVM w Scikit-learn jest implementowany w klasie `SVC`. Wypróbujmy podstawową wersję, bez tuningu hiperparametrów. Przy okazji wiemy, że złożoność kernel SVM to co najmniej $O(n^2)$ - zobaczmy, ile to zajmuje w praktyce.\n",
    "\n",
    "Warto zawsze ustawić nieco wyższą wartość `cache_size` niż domyślna. Jest to ilość MB na cache'owanie obliczonych wartości kerneli. Warto jednak uważać na zbyt duże wartości:\n",
    "- wartości ponad 2000 mogą [powodować problemy przez buga w LibSVM](https://github.com/scikit-learn/scikit-learn/issues/8012)\n",
    "- sama alokacja dużej ilości pamięci (ciągłej!) może zajmować dużo czasu\n",
    "- nie wszystkie wartości kerneli będą używane często, więc nie wszystkie jest sens cache'ować"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 94.92%\n",
      "Training time: 28.377240657806396 s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "clf_kernel_svc = SVC(cache_size=512, class_weight=\"balanced\", random_state=0)\n",
    "start_time = time()\n",
    "clf_kernel_svc.fit(X_train_scaled, y_train)\n",
    "end_time = time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "y_pred = clf_kernel_svc.predict(X_test_scaled)\n",
    "\n",
    "print(f\"F1-score: {100 * f1_score(y_test, y_pred):.2f}%\")\n",
    "print(f\"Training time: {training_time} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wynik jest ewidentnie lepszy, bez żadnego tuningu! Zajmuje to jednak sporo czasu. Ale nasz zbiór treningowy to ok. 60 tysięcy, a testowy 270 tysięcy - może to predykcja tyle zajmuje, a nie sam trening?\n",
    "\n",
    "**Zadanie 4 (1 punkt)**\n",
    "\n",
    "1. Sprawdź liczbę support vectors dla liniowego i kernel SVM. Sprawdź, jaki procent wszystkich punktów one stanowią. Czy rzadkość (sparsity) została osiągnięta? Może się przydać [ten przykład](https://scikit-learn.org/stable/auto_examples/svm/plot_linearsvc_support_vectors.html), żeby zliczyć support vectors dla liniowego SVM (`X` to u nas `X_train_scaled`).\n",
    "2. Porównaj czas predykcji na zbiorze testowym dla regresji logistycznej, liniowego SVM i kernel SVM. Uwzględniając rozmiar zbioru testowego, czy twoim zdaniem to dużo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24221\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "\n",
    "decision_function = linear_svm_cv.decision_function(X_train_scaled)\n",
    "support_vector_indices = np.where(np.abs(decision_function) <= 1 + 1e-15)[0]\n",
    "print(len(support_vector_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9524\n"
     ]
    }
   ],
   "source": [
    "print(len(clf_kernel_svc.support_vectors_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression prediction time: 0.012307405471801758 s\n",
      "Linear SVM prediction time: 0.01882457733154297 s\n",
      "Kernel SVM prediction time: 106.79165077209473 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "y_pred = clf_log_reg.predict(X_test_scaled)\n",
    "end_time = time()\n",
    "prediction_time = end_time - start_time\n",
    "print(f\"Logistic Regression prediction time: {prediction_time} s\")\n",
    "\n",
    "start_time = time()\n",
    "y_pred = linear_svm_cv.predict(X_test_scaled)\n",
    "end_time = time()\n",
    "prediction_time = end_time - start_time\n",
    "print(f\"Linear SVM prediction time: {prediction_time} s\")\n",
    "\n",
    "start_time = time()\n",
    "clf_kernel_svc.predict(X_test_scaled)\n",
    "end_time = time()\n",
    "prediction_time = end_time - start_time\n",
    "print(f\"Kernel SVM prediction time: {prediction_time} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nie udało mi się znaleźć definicji sprasity, ale w liniowym SVM uzyskaliśmy liczbę support vectorów równą około 50% (27k z około 60k) a więc ciężko tutaj mówić o sparsity. W przypadku kernel SVM jest to nieco mniej, ale wciąż liczba oscyluje dookoła kilkunastu procent.\n",
    "\n",
    "Predykcja nie trwała strasznie długo, ale w porównaniu do regresji i liniowego SVM które uzyskały podobne rezultaty jest to całkiem sporo. Patrząc jednak na rozmiar datasetu (270k) czas ten wydaje się dosyć krótki (zwłaszcza porównując to np. z sieciami neuronowymi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taki zbiór jest już dość ekstremalny dla kernel SVM. Tego algorytmu w praktyce nie stosuje się wprost dla zbiorów wielkości dziesiątek tysięcy próbek treningowych, bo byłoby to zbyt wolne. Można tu natomiast zastosować podobną sztuczkę, co z kNN i ANN, czyli aproksymować - w tym wypadku macierz kerneli. Dotyczy tego zadanie dodatkowe.\n",
    "\n",
    "Dodatkowo implementacja ze Scikit-learn potrafi być zaskakująco wolna. W praktyce LibSVM, użyty jako [samodzielna biblioteka](https://pypi.org/project/libsvm-official/), potrafi być o wiele szybszy. Ma za to dużo brzydszy interfejs.\n",
    "\n",
    "W praktyce kernel SVM jest używany najczęściej, kiedy mamy mało danych i trzeba bardzo dokładnego klasyfikatora, a jego duży koszt nie jest tak odczuwalny."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mały zbiór danych do klasyfikacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako drugi zbiór wykorzystamy [Iranian Churn Dataset](https://archive.ics.uci.edu/ml/datasets/Iranian+Churn+Dataset) ([Kaggle](https://www.kaggle.com/datasets/royjafari/customer-churn)). Dotyczy on klasyfikacji, czy dany klient telekomunikacyjny zmieni dostawcę, czyli nastąpi tzw. odpływ klienta (*customer churn*). Jest to bardzo ważne i częste zadanie w telekomunikacji i usługach, szczególnie w biznesach, gdzie pozyskanie całkiem nowych klientów jest bardzo trudne albo praktycznie niemożliwe, a trzeba ich w praktyce odebrać konkurencji. To właśnie sytuacja firm telekomunikacyjnych - telefon czy internet ma praktycznie każdy, więc zdobywanie nowych klientów jest drogie. Dużo bardziej opłaca się identyfikować \"ryzykownych\" klientów i ich zachęcić do pozostania, np. promocjami.\n",
    "\n",
    "Dane zostały pozyskane z irańskich firm telekomunikacyjnych (konkretnie z call center obsługującego takie firmy). [Historia telekomunikacji w Iranie](https://en.wikipedia.org/wiki/Communications_in_Iran) jest ciekawa sama w sobie i pokazuje, czemu w tym kraju to było szczególnie ważne. Iran w 2008 roku miał populację ponad 80 milionów ludzi, z czego około 56% poniżej 25 roku życia - idealny i duży rynek dla nowych technologii. Ponadto samo zainteresowanie było ogromne, a tempo rozwoju kraju oraz prywatyzacja państwowych spółek stworzyły niesamowicie konkurencyjny rynek. Churn prediction stało się bardzo ważnym finansowo zadaniem dla wielu spółek.\n",
    "\n",
    "Z perspektywy ML, churn prediction to praktycznie zawsze klasyfikacja binarna i niezbalanansowana - zwykle mało który klient odchodzi.\n",
    "\n",
    "Zbiór ten został zebrany przez autorów na potrzeby artykułu:\n",
    "\n",
    "> Keramati, Abbas, and Seyed MS Ardabili. *\"Churn analysis for an Iranian mobile operator.\"* Telecommunications Policy 35.4 (2011): 344-356.\n",
    "\n",
    "Churn prediction z użyciem tego zbioru zostało przez nich zastosowane w artykułach:\n",
    "\n",
    "> Keramati, Abbas, et al. *\"Improved churn prediction in telecommunication industry using data mining techniques.\"* Applied Soft Computing 24 (2014): 994-1012.\n",
    "\n",
    "> Jafari-Marandi, Ruholla, et al. *\"Optimum profit-driven churn decision making: innovative artificial neural networks in telecom industry.\"* Neural Computing and Applications 32 (2020): 14929-14962.\n",
    "\n",
    "Dane są wysokiej jakości - ludzi monitorowano przez 12 miesięcy, aby uzyskać miarodajną informację w czasie, czy odejdą do innego operatora. Dodatkowo nie mają wartości brakujących i outlierów, a wszystkie zmienne są numeryczne. Zastosowaną w artykułach metryką jest F1-score.\n",
    "\n",
    "Zbiór został wzięty z Kaggle (opublikował go tam Ruholla Jafari-Marandi). W dodatku do zmiennych opisanych na stronie UCI, zawiera on oszacowaną wartość FP i FN dla każdego klienta. Wykorzystamy to później - w końcu utrata dużo płacącego klienta jest bardziej kosztowna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 5 (1 punkt)**\n",
    "\n",
    "1. Wczytaj dane z pliku `customer_churn_data.csv`.\n",
    "2. Wyodrębnij kolumny do zmiennych:\n",
    "   - `Churn` do zmiennej `y`\n",
    "   - `FN` do zmiennej `fn_cost`\n",
    "   - `FP` do zmiennej `fp_cost`\n",
    "3. Narysuj wykres słupkowy (bar plot) częstości klas. Pamiętaj o opisaniu wykresu.\n",
    "4. Podziel zbiór na treningowy i testowy w proporcjach 75%-25% ze stratyfikacją. Pamiętaj o stałym `random_state=0`. Uwaga - podziel też `fn_cost` oraz `fp_cost` na treningowe i testowe.\n",
    "5. Dokonaj standaryzacji zmiennych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"customer_churn_data.csv\")\n",
    "\n",
    "y = X.pop(\"Churn\")\n",
    "fn_cost = X.pop(\"FN\")\n",
    "fp_cost = X.pop(\"FP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class frequencies')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_frequencies = y.value_counts() / y.count()\n",
    "class_frequencies = class_frequencies.sort_index()\n",
    "# class_frequencies.index = []\n",
    "\n",
    "ax = class_frequencies.plot.bar(rot=0)\n",
    "plt.title(\"Class frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    fn_cost_train,\n",
    "    fn_cost_test,\n",
    "    fp_cost_train,\n",
    "    fp_cost_test,\n",
    ") = train_test_split(X, y, fn_cost, fp_cost, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 6 (1.5 punktu)**\n",
    "\n",
    "1. Wytrenuj regresję logistyczną jako baseline, dokonując tuningu analogicznie do zadania 2. Pamiętaj o ustawieniu `random_state=0`. Zmierz czas treningu (włącznie z tuningiem). Sprawdź F1-score na zbiorze testowym\n",
    "2. Wytrenuj liniowy SVM:\n",
    "   - ustaw maksymalnie 10000 iteracji i zbalansowane wagi klas\n",
    "   - dokonaj tuningu hiperparametru `C` za pomocą 5-krotnej walidacji skrośnej\n",
    "   - sprawdź 100 wartości z zakresu od $10^{-2}$ do $10^2$\n",
    "   - wypisz znalezioną optymalną wartość `C`\n",
    "   - wybierz model o najwyższym F1-score\n",
    "   - zmierz czas treningu (włącznie z tuningiem)\n",
    "   - sprawdź F1-score na zbiorze testowym\n",
    "   - pamiętaj o ustawieniu `random_state=0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.8880047798156738 s\n",
      "Finetuned param: [0.01]\n",
      "F1-score: 67.56%\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "clf_log_reg = LogisticRegressionCV(\n",
    "    max_iter=10000,\n",
    "    Cs=list(np.logspace(-2, 2, 100)),\n",
    "    penalty=\"l2\",\n",
    "    class_weight=\"balanced\",\n",
    "    scoring=\"f1\",\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    ").fit(X_train, y_train)\n",
    "end_time = time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(f\"Training time: {training_time} s\")\n",
    "print(f\"Finetuned param: {clf_log_reg.C_}\")\n",
    "y_pred = clf_log_reg.predict(X_test)\n",
    "print(f\"F1-score: {100 * f1_score(y_test, y_pred):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 7 (2 punkty)**\n",
    "\n",
    "1. Wytrenuj kernel SVM z domyślnymi hiperparametrami:\n",
    "   - ustaw zbalansowane wagi klas\n",
    "   - zmierz czas treningu (włącznie z tuningiem)\n",
    "   - sprawdź F1-score na zbiorze testowym\n",
    "   - zmierz czas treningu\n",
    "   - pamiętaj o ustawieniu `random_state=0`\n",
    "2. Wytrenuj kernel SVM z tuningiem hiperparametrów:\n",
    "   - sprawdź kilka siatek hiperparametrów (`param_grid` może być listą słowników!)\n",
    "   - dla kerneli RBF sprawdź 20 wartości `C` z zakresu od $10^{-2}$ do $10^2$, a dla `gamma` sprawdź wartość `\"scale\"` oraz 20 wartości z zakresu od $10^{-2}$ do $10^2$\n",
    "   - dla kernela wielomianowego sprawdź 100 wartości `C` z zakresu od $10^{-2}$ do $10^2$ oraz stopnie wielomianu z zakresu [2, 5]\n",
    "   - dla kernela sigmoidalnego sprawdź te same zakresy wartości, co dla RBF\n",
    "3. Dokonaj analizy hiperparametrów po tuningu:\n",
    "   - sprawdź, dla jakich hiperparametrów osiągnięto najwyższy wynik walidacji skrośnej\n",
    "   - sprawdź, jaki był najlepszy wynik osiągnięty dla każdego z trzech kerneli\n",
    "   - wypisz hiperparametry dla każdego z tych przypadków\n",
    "   - który kernel wymagał najmocniejszej regularyzacji i jak sądzisz, czemu ten?\n",
    "   - wytrenuj SVM dla optymalnych hiperparametrów dla każdego z trzech kerneli i sprawdź F1-score na zbiorze testowym\n",
    "   - czy udało się dobrze oszacować wynik za pomocą walidacji skrośnej, tj. czy faktycznie kernel o najwyższym wyniku walidacyjnym miał najwyższy wynik testowy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 71.62%\n",
      "Training time: 0.08987069129943848 s\n"
     ]
    }
   ],
   "source": [
    "clf_kernel_svc = SVC(class_weight=\"balanced\", random_state=0)\n",
    "start_time = time()\n",
    "clf_kernel_svc.fit(X_train, y_train)\n",
    "end_time = time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "y_pred = clf_kernel_svc.predict(X_test)\n",
    "\n",
    "print(f\"F1-score: {100 * f1_score(y_test, y_pred):.2f}%\")\n",
    "print(f\"Training time: {training_time} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        \"kernel\": [\"rbf\"],\n",
    "        \"C\": np.logspace(-2, 2, 20),\n",
    "        \"gamma\": [\"scale\"] + list(np.logspace(-2, 2, 20)),\n",
    "    },\n",
    "    {\n",
    "        \"kernel\": [\"poly\"],\n",
    "        \"C\": np.logspace(-2, 2, 100),\n",
    "        \"degree\": [2, 3, 4, 5],\n",
    "    },\n",
    "    {\n",
    "        \"kernel\": [\"sigmoid\"],\n",
    "        \"C\": np.logspace(-2, 2, 20),\n",
    "        \"gamma\": [\"scale\"] + list(np.logspace(-2, 2, 20)),\n",
    "    },\n",
    "]\n",
    "kernel_svm_cv = GridSearchCV(SVC(), param_grid, scoring=\"f1\", n_jobs=-1).fit(\n",
    "    X_train, y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 100.0, 'gamma': 0.06951927961775606, 'kernel': 'rbf'},\n",
       " 0.8591833416819943)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_svm_cv.best_params_, kernel_svm_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.092170</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>0.033316</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.01</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'C': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.093988</td>\n",
       "      <td>0.010618</td>\n",
       "      <td>0.029599</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100659</td>\n",
       "      <td>0.021873</td>\n",
       "      <td>0.033006</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.016238</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.016237767391887217, 'ke...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.092170      0.010623         0.033316        0.002549    0.01   \n",
       "1       0.093988      0.010618         0.029599        0.002071    0.01   \n",
       "2       0.100659      0.021873         0.033006        0.004467    0.01   \n",
       "\n",
       "  param_gamma param_kernel param_degree  \\\n",
       "0       scale          rbf          NaN   \n",
       "1        0.01          rbf          NaN   \n",
       "2    0.016238          rbf          NaN   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0     {'C': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}                0.0   \n",
       "1        {'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}                0.0   \n",
       "2  {'C': 0.01, 'gamma': 0.016237767391887217, 'ke...                0.0   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.0             0.0             1136  \n",
       "1              0.0             0.0             1136  \n",
       "2              0.0             0.0             1136  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(kernel_svm_cv.cv_results_)\n",
    "results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF - params: {'C': 100.0, 'gamma': 0.06951927961775606, 'kernel': 'rbf'}, score: 0.8591833416819943\n"
     ]
    }
   ],
   "source": [
    "best_rbf_idx = results[results[\"param_kernel\"] == \"rbf\"][\"mean_test_score\"].idxmax()\n",
    "params = results.loc[best_rbf_idx][\"params\"]\n",
    "score = results.loc[best_rbf_idx][\"mean_test_score\"]\n",
    "print(f\"RBF - params: {params}, score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly - params: {'C': 91.11627561154896, 'degree': 5, 'kernel': 'poly'}, score: 0.8218438293750945\n"
     ]
    }
   ],
   "source": [
    "best_poly_idx = results[results[\"param_kernel\"] == \"poly\"][\"mean_test_score\"].idxmax()\n",
    "params = results.loc[best_poly_idx][\"params\"]\n",
    "score = results.loc[best_poly_idx][\"mean_test_score\"]\n",
    "print(f\"Poly - params: {params}, score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid - params: {'C': 37.92690190732246, 'gamma': 0.026366508987303583, 'kernel': 'sigmoid'}, score: 0.536616485081368\n"
     ]
    }
   ],
   "source": [
    "best_sigmoid_idx = results[results[\"param_kernel\"] == \"sigmoid\"][\n",
    "    \"mean_test_score\"\n",
    "].idxmax()\n",
    "params = results.loc[best_sigmoid_idx][\"params\"]\n",
    "score = results.loc[best_sigmoid_idx][\"mean_test_score\"]\n",
    "print(f\"Sigmoid - params: {params}, score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Największej regularyzacji wymagał kernel RBF, ale nie rozumiem skąd akurat taka zależność i po (niezbyt długim) researchu nie mogłem znaleźć kalrownej odpowiedzi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF F1-score: 84.21%\n"
     ]
    }
   ],
   "source": [
    "clf_kernel_svc = SVC(\n",
    "    class_weight=\"balanced\",\n",
    "    C=100,\n",
    "    gamma=0.06951927961775606,\n",
    "    kernel=\"rbf\",\n",
    "    random_state=0,\n",
    ")\n",
    "clf_kernel_svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_kernel_svc.predict(X_test)\n",
    "\n",
    "print(f\"RBF F1-score: {100 * f1_score(y_test, y_pred):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly F1-score: 81.29%\n"
     ]
    }
   ],
   "source": [
    "clf_kernel_svc = SVC(\n",
    "    class_weight=\"balanced\",\n",
    "    C=91.11627561154896,\n",
    "    degree=5,\n",
    "    kernel=\"poly\",\n",
    "    random_state=0,\n",
    ")\n",
    "clf_kernel_svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_kernel_svc.predict(X_test)\n",
    "\n",
    "print(f\"Poly F1-score: {100 * f1_score(y_test, y_pred):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid F1-score: 53.69%\n"
     ]
    }
   ],
   "source": [
    "clf_kernel_svc = SVC(\n",
    "    class_weight=\"balanced\",\n",
    "    C=37.92690190732246,\n",
    "    gamma=0.026366508987303583,\n",
    "    kernel=\"sigmoid\",\n",
    "    random_state=0,\n",
    ")\n",
    "clf_kernel_svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_kernel_svc.predict(X_test)\n",
    "\n",
    "print(f\"Sigmoid F1-score: {100 * f1_score(y_test, y_pred):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Udało się dobrze oszacować. RBF faktycznie ał najlepszy wynik na zbiorze testowym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nie uwzględniliśmy jednak jeszcze faktu, że nasi klienci mają różną wagę. Według badań koszt zyskania klienta jest około 15 razy wyższy od kosztu utrzymania klienta, który jest zagrożony przejściem dla konkurencji. W związku z tym FP i FN mają różną ważnośc. Dodatkowo sami klienci płacą mniej lub więcej, więc to też trzeba uwzględnić. Na szczęście my mamy już to zrobione, bo mamy macierze `fp_cost` oraz `fn_cost` oznaczające koszt pomylenia się na oba sposoby w przypadku każdego klienta.\n",
    "\n",
    "Powinniśmy zatem używać **ważonej metryki (weighted metric)**, która dla każdego przykładu stosuje odpowiednią wagę, i to w zależności od tego, w jaki sposób się pomyliliśmy. Tego typu metryki typowo działają jak funkcje kosztu - im mniejsza wartość, tym lepiej, bo często dosłownie reprezentują koszt, jaki firma musi ponieść przy stosowaniu danego algorytmu. Wykorzystanie takiej metryki to **cost-sensitive classification**.\n",
    "\n",
    "**Zadanie 8 (0.5 punktu)**\n",
    "\n",
    "1. Uzupełnij kod funkcji `churn_cost()`, która oblicza koszt dokonania danej klasyfikacji.\n",
    "2. Stwórz funkcję w postaci akceptowanej przez `GridSearchCV` za pomocą `make_scorer`. Zwróć uwagę, żeby podać do niej prawidłowe argumenty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "def churn_cost(\n",
    "    y_true: Union[np.ndarray, pd.Series],\n",
    "    y_pred: Union[np.ndarray, pd.Series],\n",
    "    fp_cost: Union[np.ndarray, pd.Series],\n",
    "    fn_cost: Union[np.ndarray, pd.Series],\n",
    ") -> float:\n",
    "    # make sure all data is Numpy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    fp_cost = np.array(fp_cost)\n",
    "    fn_cost = np.array(fn_cost)\n",
    "\n",
    "    # check which rows are for FP and FN\n",
    "    fp_idx = np.where((y_true == 0) & (y_pred == 1))\n",
    "    fn_idx = np.where((y_true == 1) & (y_pred == 0))\n",
    "    # get costs for FP and FN\n",
    "    # return sum of costs\n",
    "    return np.sum(fp_cost[fp_idx]) + np.sum(fn_cost[fn_idx])\n",
    "\n",
    "\n",
    "churn_cost_score = make_scorer(\n",
    "    churn_cost,\n",
    "    greater_is_better=False,\n",
    "    y_test=y_test,\n",
    "    fp_cost=fp_cost_test,\n",
    "    fn_cost=fn_cost_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 9 (1 punkt)**\n",
    "\n",
    "1. Wytrenuj klasyfikatory stały `DummyClassifier`:\n",
    "   - taki, który zawsze przewiduje klasę negatywną (brak zmiany)\n",
    "   - taki, który zawsze przewiduje klasę pozytywną (churn)\n",
    "2. Sprawdź metrykę F1-score oraz nasz nowo zdefiniowany churn cost dla takich rozwiązań na zbiorze testowym. Wykorzystaj `fp_cost_test` oraz `fn_cost_test`.\n",
    "3. Lepiej jest stosować reklamy dla wszystkich, czy po prostu zgodzić się na churn i nic z tym nie robić? Uwzględniając liczbę próbek w zbiorze testowym, czy twoim zdaniem wysoki koszt? Załóż, że walutą są dolary - irański rial zawsze był tak słabą walutą, że i tak używano walut zagranicznych, co widać też w tym zbiorze. Wartość każdego klienta jest typowo wysoka, bo to obliczona tzw. lifetime value - przewidywana potencjalna wartość klienta w przyszłości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Dummy F1-score: 0.00%\n",
      "Positive Dummy F1-score: 30.17%\n",
      "Negative Dummy churn cost: 16153\n",
      "Positive Dummy churn cost: 67459\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_neg_clf = DummyClassifier(strategy=\"constant\", constant=0)\n",
    "dummy_neg_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_neg = dummy_neg_clf.predict(X_test)\n",
    "\n",
    "dummy_pos_clf = DummyClassifier(strategy=\"constant\", constant=1)\n",
    "dummy_pos_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_pos = dummy_pos_clf.predict(X_test)\n",
    "\n",
    "print(f\"Negative Dummy F1-score: {100 * f1_score(y_test, y_pred_neg):.2f}%\")\n",
    "print(f\"Positive Dummy F1-score: {100 * f1_score(y_test, y_pred_pos):.2f}%\")\n",
    "\n",
    "print(f\"Negative Dummy churn cost: {churn_cost(y_test, y_pred_neg, fp_cost_test, fn_cost_test):.0f}\")\n",
    "print(f\"Positive Dummy churn cost: {churn_cost(y_test, y_pred_pos, fp_cost_test, fn_cost_test):.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przewidując, że w ogóle nie będzie churnu (klienci nie odpłyną) straciliśmy mniej pieniędzy niż zakładając, że wszyscy mogą odejść."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 10 (1 punkt)**\n",
    "\n",
    "1. Wytrenuj liniowy SVM, wykorzystaj znalezioną wcześniej optymalną wartość `C`. Innych parametrów użyj tak, jak wcześniej. Jaki jest koszt przy wdrożeniu takiego rozwiązania? Ile zyskujemy względem najlepszego rozwiązania z poprzedniego zadania?\n",
    "2. Wytrenuj kernel SVM, wykorzystaj znalezione wcześniej optymalne wartości hiperparametrów. Innych parametrów użyj tak, jak wcześniej. O ile lepszy jest koszt? O ile lepszy jest od modelu liniowego, jakim jest liniowy SVM?\n",
    "3. Czy twoim zdaniem warto wdrażać rozwiązania oparte o ML do takich zadań?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// skomentuj tutaj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie dodatkowe (3 punkty)\n",
    "\n",
    "W przypadku, kiedy zastosowanie kernel SVM wprost byłoby zbyt kosztowne, można zamiast tego przybliżyć cechy kernelowe. Realizują to algorytmy grupy kernel approximation.\n",
    "\n",
    "Metoda Nyströma to algorytm uniwersalny, który potrafi przybliżyć dowolny kernel. Wykorzystuje do tego truncated SVD, czyli przybliża wprost kernel matrix za pomocą macierzy niższej rangi. Ceną tej prostoty i uniwersalności jest nie najlepsza prędkość działania w porównaniu do bardziej specjalistycznych algorytmów. Proste wyprowadzenie tej metody można znaleźć [tutaj](https://stats.stackexchange.com/questions/261149/nystroem-method-for-kernel-approximation).\n",
    "\n",
    "`RBFSampler` w Scikit-learn implementuje metodę Random Kitchen Sinks. Ten algorytm za pomocą próbkowania Monte Carlo przybliża coraz lepiej macierz kernela RBF. W bibliotece Scikit-learn-extra zaimplementowane jest rozwinięcie tego algorytmu o nazwie [Fastfood](https://scikit-learn-extra.readthedocs.io/en/stable/generated/sklearn_extra.kernel_approximation.Fastfood.html), który stosuje nieco bardziej zaawansowany algorytm przybliżający, który powinien być jeszcze szybszy i oszczędniejszy pamięciowo.\n",
    "\n",
    "Hiperparametry tych metod są podobne do zwykłego kernel SVM, ale dodatkowo mamy wymiarowość naszego przybliżenia, czyli `n_components`. Im większe, tym dokładniej przybliżamy, ale też tym więcej mamy cech. Wejściem do metody Nyströma jest macierz cech X, a wyjściem macierz cech kernelowych X mająca rozmiar `n_samples * n_components`. Na takich cechach trenuje się już zwykły liniowy SVM.\n",
    "\n",
    "1. Zaimplementuj `Pipeline` składający się z przybliżenia kernela oraz liniowego SVM: dla metody Nyströma, oraz dla obu algorytmów dla kernela RBF.\n",
    "2. Wytrenuj algorytmy z domyślnymi hiperparametrami. Porównaj jakość predykcji oraz szybkość z liniowym SVM i z kernel SVM. Czy warto dokonać takiej aproksymacji?\n",
    "3. Dokonaj optymalizacji hiperparametrów `C`, `gamma` oraz `n_components`. Czy udało się poprawić wynik względem zwykłego kernel SVM w rozsądnym czasie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// skomentuj tutaj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
